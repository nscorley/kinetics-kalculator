{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "sys.path.append(\"/home/ach94/scripts/\")\n",
    "# sys.path.append(\"/home/ach94/scripts/spellock\")\n",
    "# import kinetics\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "import scipy.stats as stat\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mscarlett_and_kinetics(filepath, start_row=54):\n",
    "    \"\"\"\n",
    "    parse a tab delimited plate reader text fuke from synergy neo2 with mscarlett and kinetic reads in the same file.\n",
    "\n",
    "    inputs\n",
    "    filepath (string) - string specifying the filepath\n",
    "    start_row (int) - start row for the mscarlett data\n",
    "\n",
    "    outputs\n",
    "    df_mscarlett (dataframe) - dataframe containing mscarlet reads in tidy format\n",
    "    df_kinetics (dataframe) - dataframe containing kinetic reads in tidy format\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## parse replicate number\n",
    "    # Use regex to find the substring \"plate\" followed by a number\n",
    "    match = re.search(r\"plate(\\d+)\", filepath)\n",
    "\n",
    "    # If a match is found, extract the value next to \"plate\"\n",
    "    if match:\n",
    "        replicate_number = int(match.group(1))\n",
    "    else:\n",
    "        print(\n",
    "            \"No replicate number found, be sure to include sample# in the file name where # is the replicate number\"\n",
    "        )\n",
    "\n",
    "    ## parse experiment ID\n",
    "\n",
    "    ## parse plate ID\n",
    "    match = re.search(r\"sample(\\d+)\", filepath)\n",
    "\n",
    "    # If a match is found, extract the value next to \"sample\"\n",
    "    if match:\n",
    "        sample_number = int(match.group(1))\n",
    "    else:\n",
    "        print(\n",
    "            \"No plate number found, be sure to include plate# in the file name where # is the plate number\"\n",
    "        )\n",
    "\n",
    "    # print(f\"parsing plate {sample_number} replicate {replicate_number}\")\n",
    "\n",
    "    ## parse instrument serial number\n",
    "    df = pd.read_csv(\n",
    "        filepath,\n",
    "        encoding=\"cp1252\",\n",
    "        delimiter=\"\\t\",\n",
    "        nrows=20,\n",
    "    )\n",
    "    serial_number = df[df.iloc[:, 0] == \"Reader Serial Number:\"]\n",
    "    serial_number = serial_number.iloc[:, 1].values[0]\n",
    "\n",
    "    ## parse mscarlett data\n",
    "    df_mscarlett = pd.read_csv(\n",
    "        filepath,\n",
    "        encoding=\"cp1252\",\n",
    "        delimiter=\"\\t\",\n",
    "        skiprows=range(1, start_row),\n",
    "        nrows=1,\n",
    "    )\n",
    "\n",
    "    # make dataframe tidy\n",
    "    df_mscarlett = df_mscarlett.melt(\n",
    "        id_vars=[\"Well\"], var_name=\"well\", value_name=\"value\"\n",
    "    )\n",
    "    df_mscarlett.dropna(inplace=True)\n",
    "\n",
    "    # clean the naming\n",
    "    df_mscarlett.drop(columns=[\"Well\"], inplace=True)\n",
    "\n",
    "    # add info\n",
    "    df_mscarlett[\"serial_number\"] = serial_number\n",
    "    # df_mscarlett[\"replicate_number\"] = replicate_number\n",
    "    # df_mscarlett[\"sample_number\"] = sample_number\n",
    "\n",
    "    ## parse kinetics data\n",
    "    df_kinetics = pd.read_csv(\n",
    "        filepath,\n",
    "        encoding=\"cp1252\",\n",
    "        delimiter=\"\\t\",\n",
    "        # header=0,\n",
    "        skiprows=range(1, start_row + 4),\n",
    "    )\n",
    "\n",
    "    df_kinetics = df_kinetics.drop(df_kinetics.columns[1], axis=1)\n",
    "    df_kinetics.rename(columns={\"Time\": \"time\"}, inplace=True)\n",
    "\n",
    "    # time conversion\n",
    "    df_kinetics[\"time\"] = pd.to_datetime(\n",
    "        df_kinetics[\"time\"], format=\"%H:%M:%S\", errors=\"coerce\"\n",
    "    ).dt.time\n",
    "\n",
    "    # Convert the time column to seconds\n",
    "    df_kinetics[\"time\"] = df_kinetics[\"time\"].apply(\n",
    "        lambda x: x.hour * 3600 + x.minute * 60 + x.second\n",
    "    )\n",
    "\n",
    "    # make dataframe tidy\n",
    "    df_kinetics = df_kinetics.melt(\n",
    "        id_vars=[\"time\"], var_name=\"well\", value_name=\"value\"\n",
    "    )\n",
    "    df_kinetics.dropna(inplace=True)\n",
    "\n",
    "    # add info\n",
    "    df_kinetics[\"serial_number\"] = serial_number\n",
    "    # df_kinetics[\"replicate_number\"] = replicate_number\n",
    "    # df_kinetics[\"sample_number\"] = sample_number\n",
    "\n",
    "    # clean dataframe data types\n",
    "    df_kinetics[\"value\"] = pd.to_numeric(df_kinetics[\"value\"], errors=\"coerce\")\n",
    "\n",
    "    return df_mscarlett, df_kinetics\n",
    "\n",
    "\n",
    "# Read the FASTA file and convert it to a DataFrame\n",
    "def fasta_to_dataframe(fasta_file):\n",
    "    records = SeqIO.parse(fasta_file, \"fasta\")\n",
    "    data = [(record.id, str(record.seq)) for record in records]\n",
    "    df = pd.DataFrame(data, columns=[\"ID\", \"sequence\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def fit_line(group, x_column=\"time\", y_column=\"4MU_um\"):\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(\n",
    "        group[x_column], group[y_column]\n",
    "    )\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"rate\": slope,\n",
    "            \"intercept\": intercept,\n",
    "            \"r_value\": r_value,\n",
    "            \"p_value\": p_value,\n",
    "            \"std_err\": std_err,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# def subtract_background(group):\n",
    "#     background = group.loc[group[\"sample_type\"] == \"negative_control\", \"rate\"].values[0]\n",
    "#     group[\"rate_minus_background\"] = group[\"rate\"] - background\n",
    "#     return group\n",
    "\n",
    "\n",
    "def set_plt_size(w, h, ax=None):\n",
    "    \"\"\"w, h: width, height in inches\"\"\"\n",
    "    # Allows for specification of matplotlib figure area (excluding axes labels etc.)\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w) / (r - l)\n",
    "    figh = float(h) / (t - b)\n",
    "    ax.figure.set_size_inches(figw, figh)\n",
    "\n",
    "\n",
    "def parity_plot(reps, params):\n",
    "\n",
    "    from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "    alpha, ax_label, stat_val = params\n",
    "\n",
    "    # Set scale for plot and calculate parity line\n",
    "    n = len(reps)\n",
    "\n",
    "    max_val = []\n",
    "    min_val = []\n",
    "    for i in range(n):\n",
    "        max_val.append(max(reps[i]))\n",
    "        min_val.append(min(reps[i]))\n",
    "\n",
    "    data_len = np.absolute(max(max_val) - min(min_val))\n",
    "    # print(data_len)\n",
    "    parity = [min(min_val) - 0.05 * data_len, max(max_val) + 0.05 * data_len]\n",
    "\n",
    "    # plotting fluorescence agains eachother\n",
    "    fig, ax = plt.subplots(sharex=True, sharey=True, figsize=(12, 12))\n",
    "\n",
    "    # plot replicate data\n",
    "    ax.scatter(reps[0], reps[1], color=\"black\", alpha=alpha)\n",
    "    # turn minor ticks off, since it is somehow impossible to turn minor x ticks on\n",
    "    #     ax.tick_params(axis='y', which='minor', left=False)\n",
    "\n",
    "    # parity=[min([ax.get_xlim()[0],ax.get_ylim()[0]]),max([ax.get_xlim()[1],ax.get_ylim()[1]])]\n",
    "\n",
    "    # Plot parity line\n",
    "    ax.plot(parity, parity, \"k-\", lw=1)\n",
    "\n",
    "    # Set axis labeles to be the same\n",
    "    ax.set_aspect(\"equal\", \"box\")\n",
    "    # ax.yaxis.set_ticks(ax.get_xticks())\n",
    "    # ax.xaxis.set_ticks(ax.get_yticks())\n",
    "\n",
    "    # Ensure the parity line is the limits\n",
    "    ax.set_xlim(parity)\n",
    "    ax.set_ylim(parity)\n",
    "\n",
    "    # Calculate stats\n",
    "    r = stat.pearsonr(reps[0], reps[1])[0]\n",
    "    [m, b, R, p, std_err] = stat.linregress(reps[0], reps[1])\n",
    "\n",
    "    # calculate the postion (in data units) for text\n",
    "    parity_len = np.absolute(parity[1] - parity[0])\n",
    "    text_pos = [0.05 * parity_len + parity[0], parity[1] - 0.1 * parity_len]\n",
    "\n",
    "    # add text to plots\n",
    "    if stat_val == \"r\":\n",
    "        # add pearson correlation\n",
    "        ax.text(text_pos[0], text_pos[1], \"r = \" + str(np.round(r, 3)), fontsize=14)\n",
    "    elif stat_val == \"R\":\n",
    "        # to display R**2 value for linear fit, use below\n",
    "        ax.text(\n",
    "            text_pos[0], text_pos[1], \"R$^{2}$ = \" + str(np.round(R**2, 3)), fontsize=14\n",
    "        )\n",
    "\n",
    "    # Set axis labels for outside axes\n",
    "    ax.set_ylabel(ax_label[1])\n",
    "    ax.set_xlabel(ax_label[0])\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup the directory\n",
    "# in what directory is this notebook?\n",
    "working_directory_path = Path(\n",
    "    \"/home/ach94/projects/p13_iterative_optimization/e197_plate_repeats/\"\n",
    ")\n",
    "\n",
    "pics_directory = working_directory_path / \"pics\"\n",
    "pics_directory.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import well mappings\n",
    "\n",
    "df_mappings = pd.read_excel(\n",
    "    \"/home/ach94/projects/p12_small_molecule_acyl_transfer/e200_cys_kinetics/experimental_processed_data/241023_e200_mappings.xlsx\"\n",
    ")\n",
    "\n",
    "# clean dataframe data types\n",
    "df_mappings[\"replicate_number\"] = pd.to_numeric(\n",
    "    df_mappings[\"replicate_number\"], errors=\"coerce\"\n",
    ")\n",
    "df_mappings[\"column\"] = pd.to_numeric(df_mappings[\"column\"], errors=\"coerce\")\n",
    "\n",
    "df_mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse data\n",
    "\n",
    "filepath = \"/home/ach94/projects/p12_small_molecule_acyl_transfer/e200_cys_kinetics/experimental_raw_data/241023_e200_kinetics_1_repeat.txt\"\n",
    "# mscarlett_start_row = 54\n",
    "kinetics_start_row = 42  # mscarlett_start_row + 4\n",
    "\n",
    "## parse instrument serial number\n",
    "df = pd.read_csv(\n",
    "    filepath,\n",
    "    encoding=\"cp1252\",\n",
    "    delimiter=\"\\t\",\n",
    "    nrows=20,\n",
    ")\n",
    "serial_number = df[df.iloc[:, 0] == \"Reader Serial Number:\"]\n",
    "serial_number = serial_number.iloc[:, 1].values[0]\n",
    "\n",
    "## parse kinetics data\n",
    "df_kinetics = pd.read_csv(\n",
    "    filepath,\n",
    "    encoding=\"cp1252\",\n",
    "    delimiter=\"\\t\",\n",
    "    # header=0,\n",
    "    skiprows=range(1, kinetics_start_row),\n",
    ")\n",
    "\n",
    "df_kinetics = df_kinetics.drop(df_kinetics.columns[1], axis=1)\n",
    "df_kinetics.rename(columns={\"Time\": \"time\"}, inplace=True)\n",
    "\n",
    "# time conversion\n",
    "df_kinetics[\"time\"] = pd.to_datetime(\n",
    "    df_kinetics[\"time\"], format=\"%H:%M:%S\", errors=\"coerce\"\n",
    ").dt.time\n",
    "\n",
    "# Convert the time column to seconds\n",
    "df_kinetics[\"time\"] = df_kinetics[\"time\"].apply(\n",
    "    lambda x: x.hour * 3600 + x.minute * 60 + x.second\n",
    ")\n",
    "\n",
    "# make dataframe tidy\n",
    "df_kinetics = df_kinetics.melt(id_vars=[\"time\"], var_name=\"well\", value_name=\"value\")\n",
    "df_kinetics.dropna(inplace=True)\n",
    "\n",
    "# add info\n",
    "df_kinetics[\"serial_number\"] = serial_number\n",
    "\n",
    "# clean dataframe data types\n",
    "df_kinetics[\"value\"] = pd.to_numeric(df_kinetics[\"value\"], errors=\"coerce\")\n",
    "\n",
    "# add plate number manually\n",
    "df_kinetics[\"plate_number\"] = 1\n",
    "\n",
    "\n",
    "temp_dfs.append(df_kinetics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kinetics = pd.concat(temp_dfs)\n",
    "df_kinetics[df_kinetics[\"plate_number\"] == 2]\n",
    "\n",
    "# map data to sample info\n",
    "\n",
    "df_kinetics = df_kinetics.merge(df_mappings, on=[\"well\", \"plate_number\"], how=\"left\")\n",
    "\n",
    "df_kinetics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the mscarlett and 4MU with the standard curve\n",
    "\n",
    "standard_curve_json = \"/home/ach94/projects/p13_iterative_optimization/e191_kinetic_data_dev/241001_standard_curves.json\"\n",
    "\n",
    "with open(standard_curve_json, \"r\") as f:\n",
    "    standard_curves = json.load(f)\n",
    "\n",
    "df_kinetics[\"4MU_um\"] = df_kinetics.apply(\n",
    "    lambda x: (x[\"value\"] - standard_curves[x[\"serial_number\"]][\"4MU\"][\"y_intercept\"])\n",
    "    / standard_curves[x[\"serial_number\"]][\"4MU\"][\"slope\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_kinetics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply linear fit to 4MU data and process\n",
    "fit_time_range = (0, 400)\n",
    "\n",
    "# filter the data to the right time range\n",
    "df_temp = df_kinetics[\n",
    "    (df_kinetics[\"time\"] >= fit_time_range[0])\n",
    "    & (df_kinetics[\"time\"] <= fit_time_range[1])\n",
    "]\n",
    "\n",
    "# fit the data with a line\n",
    "df_kinetics_fits = (\n",
    "    df_temp.groupby(\n",
    "        [\n",
    "            \"well\",\n",
    "            \"replicate_number\",\n",
    "            \"name\",\n",
    "            \"sample_type\",\n",
    "            \"plate_number\",\n",
    "            \"substrate_concentration\",\n",
    "        ]\n",
    "    )\n",
    "    .apply(fit_line, x_column=\"time\", y_column=\"4MU_um\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_kinetics_fits.drop(columns=[\"r_value\", \"p_value\", \"std_err\"], inplace=True)\n",
    "\n",
    "# subract background\n",
    "value = \"rate\"\n",
    "grouping = [\"plate_number\", \"substrate_concentration\"]\n",
    "clip = True\n",
    "epsilon = 1e-8\n",
    "\n",
    "df_background_rates = (\n",
    "    df_kinetics_fits[df_kinetics_fits[\"sample_type\"] == \"negative_control\"]\n",
    "    .groupby(grouping)[value]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={value: f\"background_{value}\"})\n",
    ")\n",
    "\n",
    "if clip:\n",
    "    # df_background_rates[f\"background_{value}\"] = df_background_rates[\n",
    "    #     f\"background_{value}\"\n",
    "    # ].clip(lower=0)\n",
    "\n",
    "    df_background_rates.loc[\n",
    "        df_background_rates[f\"background_{value}\"] < 0, f\"background_{value}\"\n",
    "    ] = epsilon\n",
    "\n",
    "df_kinetics_fits = df_kinetics_fits.merge(df_background_rates, on=grouping, how=\"left\")\n",
    "\n",
    "df_kinetics_fits[f\"{value}_minus_background\"] = (\n",
    "    df_kinetics_fits[value] - df_kinetics_fits[f\"background_{value}\"]\n",
    ")\n",
    "\n",
    "# clip any rates below zero\n",
    "\n",
    "# df_kinetics_fits[f\"rate_minus_background\"] = df_kinetics_fits[\n",
    "#     f\"rate_minus_background\"\n",
    "# ].clip(lower=0)\n",
    "\n",
    "df_kinetics_fits.loc[\n",
    "    df_kinetics_fits[\"rate_minus_background\"] < 0, \"rate_minus_background\"\n",
    "] = 1e-8\n",
    "\n",
    "# merge all mapping info\n",
    "grouping = [\n",
    "    \"well\",\n",
    "    \"replicate_number\",\n",
    "    \"name\",\n",
    "    \"sample_type\",\n",
    "    \"plate_number\",\n",
    "    \"substrate_concentration\",\n",
    "]\n",
    "\n",
    "df_kinetics_fits = df_kinetics_fits.merge(df_mappings, on=grouping, how=\"left\")\n",
    "\n",
    "\n",
    "# calculate velocity\n",
    "\n",
    "df_kinetics_fits[\"velocity\"] = (\n",
    "    df_kinetics_fits[\"rate_minus_background\"] / df_kinetics_fits[\"enzyme_concentration\"]\n",
    ")\n",
    "\n",
    "df_kinetics_fits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate kinetics data\n",
    "grouping = [\"name\", \"plate_number\", \"substrate_concentration\"]\n",
    "\n",
    "df_kinetics_stats = (\n",
    "    df_kinetics_fits.groupby(grouping)[\"velocity\"]\n",
    "    .agg(\n",
    "        mean=\"mean\",\n",
    "        std_dev=\"std\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_kinetics_stats.rename(\n",
    "    columns={\n",
    "        \"mean\": \"rate_mean\",\n",
    "        \"std_dev\": \"rate_std_dev\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df_kinetics_stats[\"rate_cv\"] = df_kinetics_stats[\"rate_std_dev\"] / abs(\n",
    "    df_kinetics_stats[\"rate_mean\"]\n",
    ")\n",
    "\n",
    "\n",
    "# grouping = [\n",
    "#     \"name\",\n",
    "#     \"substrate_concentration\",\n",
    "#     \"plate_number\",\n",
    "# ]\n",
    "\n",
    "# df_kinetics_stats = df_kinetics_stats.merge(\n",
    "#     df_mappings[\n",
    "#         [\"name\", \"substrate_concentration\", \"sample_type\", \"plate_number\"]\n",
    "#     ].head(),\n",
    "#     on=grouping,\n",
    "#     how=\"left\",\n",
    "# )\n",
    "\n",
    "df_kinetics_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mappings[[\"name\", \"substrate_concentration\", \"sample_type\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_kinetics[df_kinetics[\"sample_type\"] == \"sample\"]\n",
    "\n",
    "names = df_plot.name.unique()\n",
    "num_names = len(names)\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(\n",
    "    1, num_names, figsize=(num_names * 5, 5), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "# Loop through each unique name to plot\n",
    "for num, name in enumerate(names):\n",
    "    sns.lineplot(\n",
    "        data=df_plot[df_plot[\"name\"] == name],  # Filter data for each replicate\n",
    "        x=\"time\",\n",
    "        y=\"4MU_um\",\n",
    "        hue=\"substrate_concentration\",\n",
    "        # palette=\"viridis\",\n",
    "        ax=axs[num] if num_names > 1 else axs,  # Handles single or multiple axes\n",
    "    )\n",
    "    axs[num].set_xlabel(\"Time (seconds)\")\n",
    "    axs[num].set_ylabel(\"[4MU] (uM)\")\n",
    "    axs[num].set_title(f\"{name}\")\n",
    "\n",
    "# Adjust layout for spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kinetics_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# Michaelis-Menten model\n",
    "def michaelis_menten(s, Vmax, Km):\n",
    "    return (Vmax * s) / (Km + s)\n",
    "\n",
    "\n",
    "def fit_michaelis_menten(\n",
    "    group,\n",
    "    substrate_concentrations=\"substrate_concentration\",\n",
    "    velocities=\"velocity\",\n",
    "    kcat_guess=0.001,\n",
    "    km_guess=50,\n",
    "    bounds=(0, [float(\"inf\"), float(\"inf\")]),\n",
    "):\n",
    "    # Fit the data\n",
    "    params, covariance = curve_fit(\n",
    "        michaelis_menten,\n",
    "        group[substrate_concentrations],\n",
    "        group[velocities],\n",
    "        p0=[kcat_guess, km_guess],\n",
    "        bounds=bounds,\n",
    "    )\n",
    "\n",
    "    # Get the relevant parameters\n",
    "    kcat_optimized, Km_optimized = params\n",
    "    kcat_stdev, Km_stdev = np.sqrt(np.diag(covariance))\n",
    "\n",
    "    # Calculate the uncertainty in kcat/Km by propagating errors\n",
    "    rel_kcat_unc = kcat_stdev / kcat_optimized\n",
    "    rel_Km_unc = Km_stdev / Km_optimized\n",
    "    kcat_Km_unc = (\n",
    "        kcat_optimized / Km_optimized * np.sqrt(rel_kcat_unc**2 + rel_Km_unc**2)\n",
    "    )\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"kcat\": kcat_optimized,\n",
    "            \"Km\": Km_optimized,\n",
    "            \"kcat_stdev\": kcat_stdev,\n",
    "            \"Km_stdev\": Km_stdev,\n",
    "            \"kcat_Km_uncertainty\": kcat_Km_unc,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# velocities\n",
    "\n",
    "\n",
    "df_params = df_kinetics_stats[df_kinetics_stats[\"name\"] != \"negative_control\"]\n",
    "\n",
    "# fit the data with a line\n",
    "df_params = (\n",
    "    df_params.groupby(\n",
    "        [\n",
    "            \"name\",\n",
    "        ]\n",
    "    )\n",
    "    .apply(\n",
    "        fit_michaelis_menten,\n",
    "        substrate_concentrations=\"substrate_concentration\",\n",
    "        velocities=\"rate_mean\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "df_params[\"efficiency\"] = df_params[\"kcat\"] / (df_params[\"Km\"] * 1e-6)\n",
    "\n",
    "df_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_kinetics_stats[df_kinetics_stats[\"name\"] != \"negative_control\"]\n",
    "\n",
    "names = df_plot.name.unique()\n",
    "num_names = len(names)\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, num_names, figsize=(num_names * 5, 5))\n",
    "\n",
    "# Loop through each unique name to plot\n",
    "for num, name in enumerate(names):\n",
    "    x = df_plot[df_plot[\"name\"] == name][\"substrate_concentration\"]\n",
    "    y = df_plot[df_plot[\"name\"] == name][\"rate_mean\"]\n",
    "    axs[num].scatter(x, y)\n",
    "\n",
    "    kcat = df_params[df_params[\"name\"] == name].kcat.values[0]\n",
    "    Km = df_params[df_params[\"name\"] == name].Km.values[0]\n",
    "    x_fit = np.linspace(0, max(x), 100)\n",
    "    y_fit = michaelis_menten(x_fit, kcat, Km)\n",
    "    axs[num].plot(x_fit, y_fit)\n",
    "\n",
    "    axs[num].set_xlabel(\"[4MU] (uM))\")\n",
    "    axs[num].set_ylabel(\"Rate/[E] (s$^{-1}$)\")\n",
    "    axs[num].set_title(f\"{name}\")\n",
    "\n",
    "# Adjust layout for spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinetics_kalculator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
